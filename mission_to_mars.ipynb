{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Chrome to scrape the following url\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NASA Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url for NASA Mars News Site\n",
    "news_url= 'https://mars.nasa.gov/news'\n",
    "\n",
    "# Navigate to url\n",
    "browser.visit(news_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(browser.html, 'html.parser')\n",
    "\n",
    "# Setup explicit wait time for javascript to load the webpage\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------\n",
      "News Title:\n",
      "For InSight, Dust Cleanings Will Yield New Science\n",
      "\n",
      "News Paragraph:\n",
      "Wind can be crucial to clearing dust from spacecraft solar panels on Mars. With InSight's meteorological sensors, scientists get their first measurements of wind and dust interacting \"live\" on the Martian surface.  \n",
      "\n",
      "Updated on May  6, 2019\n",
      "-------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Find the first tag in which news title and paragraph locate\n",
    "# Note that if directly searching for ('div', class_='list_text'), time.sleep(1) is unnecessary\n",
    "# It loads faster than its parental \"li\" with the class of \"slide\"\n",
    "news_tag = soup.find('li', class_='slide').find('div', class_='list_text')\n",
    "\n",
    "# Retrieve the title and paragraph for the latest news\n",
    "\n",
    "news_title = news_tag.find('div', class_='content_title').text\n",
    "news_p = news_tag.find('div', class_='article_teaser_body').text\n",
    "news_date = news_tag.find('div', class_='list_date').text\n",
    "\n",
    "# Print results\n",
    "print('-'*97)\n",
    "print('News Title:')\n",
    "print(news_title)\n",
    "print('\\nNews Paragraph:')\n",
    "print(news_p)\n",
    "print(f'\\nUpdated on {news_date}')\n",
    "print('-'*97)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPL Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url for Mars Space Image from Jet Propulsion Laboratory\n",
    "image_url= 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "\n",
    "# Navigate to url\n",
    "browser.visit(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(browser.html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"background-image: url('/spaceimages/images/wallpaper/PIA14884-1920x1200.jpg');\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve relative path for featured image\n",
    "rel_path = soup.find('article', class_='carousel_item')['style']\n",
    "\n",
    "# View \"rel_path\"\n",
    "rel_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.jpl.nasa.gov/spaceimages/images/wallpaper/PIA14884-1920x1200.jpg'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since \"/\" is not in string \"?search=&category=Mars\", rstrip() \"image_url\" for concatenation \n",
    "featured_img_url = image_url.rstrip(\"?search=&category=Mars\") + rel_path[36:-3]\n",
    "\n",
    "# Display \"featured_img_url\"\n",
    "featured_img_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url for Mars Weather on Twitter\n",
    "news_url= 'https://twitter.com/marswxreport?lang=en'\n",
    "\n",
    "# Navigate to url\n",
    "browser.visit(news_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(browser.html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Latest Mars Weather:\n",
      "InSight sol 158 (2019-05-07) low -99.7ºC (-147.5ºF) high -21.8ºC (-7.2ºF)\n",
      "winds from the SSE at 4.8 m/s (10.7 mph) gusting to 13.6 m/s (30.4 mph)\n",
      "pressure at 7.50 hPa\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Find tags that contain Mars temperature\n",
    "# Note that not all 'div' tags with the class of \"content\" is about Mars temperature tweet\n",
    "content_tags = soup.find_all('div', class_='content')\n",
    "\n",
    "# Loop through \"content\" tags\n",
    "for content in content_tags:\n",
    "    \n",
    "    try:\n",
    "        # Assign child 'div' tag with the class of \"stream-item-header\" to \"header\" \n",
    "        header = content.find('div', class_='stream-item-header')\n",
    "        \n",
    "        # Look for full name and username in stream header      \n",
    "        full_name = header.a.find('span', class_='FullNameGroup').text[1:].rstrip('\\u200f\\xa0')\n",
    "        username = header.a.find('span', class_='username').text\n",
    "\n",
    "        # Mars temperature is tweeted by \"MarsWxReport\" as \"Mars Weather\"\n",
    "        if full_name == 'Mars Weather' and username == '@MarsWxReport':\n",
    "            \n",
    "            # Retrieve content of the tweet for Mars temperature\n",
    "            # Note that if 'div' (class=\"stream-item-header\") exist, so does that with class of\n",
    "            # \"js-tweet-text-container\"\n",
    "            mars_weather = content.find('div', class_='js-tweet-text-container').p.text[:-26]\n",
    "            \n",
    "            # Jump out of iteration once the latest Mars temperature is found\n",
    "            break        \n",
    "        \n",
    "    # Set exception for \"content\" tag without child 'div' (class=\"stream-item-header\")   \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Print results\n",
    "print('-'*80)\n",
    "print('Latest Mars Weather:')\n",
    "print(mars_weather)\n",
    "print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url for Mars facts on Space Fact website\n",
    "fact_url= 'https://space-facts.com/mars/'\n",
    "\n",
    "# Navigate to url\n",
    "browser.visit(fact_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(browser.html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store data from \"Mars Planet Profile\" table\n",
    "cols = []\n",
    "\n",
    "# Anchor contents of \"Mars Planet Profile\" table\n",
    "table = soup.find('table', class_='tablepress')\n",
    "\n",
    "# Retrieve all rows from the table\n",
    "rows = table.tbody.find_all('tr')\n",
    "\n",
    "# Loop through each row to scrape column data of interest and append to \"cols\" list\n",
    "for row in rows:\n",
    "    col_queries = row.find_all('td')\n",
    "    col = [col_queries[i].text.strip() for i in range(2)]\n",
    "    cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Equatorial Diameter:</td>\n",
       "      <td>6,792 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polar Diameter:</td>\n",
       "      <td>6,752 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mass:</td>\n",
       "      <td>6.42 x 10^23 kg (10.7% Earth)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moons:</td>\n",
       "      <td>2 (Phobos &amp; Deimos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Orbit Distance:</td>\n",
       "      <td>227,943,824 km (1.52 AU)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Orbit Period:</td>\n",
       "      <td>687 days (1.9 years)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Surface Temperature:</td>\n",
       "      <td>-153 to 20 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>First Record:</td>\n",
       "      <td>2nd millennium BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Recorded By:</td>\n",
       "      <td>Egyptian astronomers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Parameters                         Values\n",
       "0  Equatorial Diameter:                       6,792 km\n",
       "1       Polar Diameter:                       6,752 km\n",
       "2                 Mass:  6.42 x 10^23 kg (10.7% Earth)\n",
       "3                Moons:            2 (Phobos & Deimos)\n",
       "4       Orbit Distance:       227,943,824 km (1.52 AU)\n",
       "5         Orbit Period:           687 days (1.9 years)\n",
       "6  Surface Temperature:                  -153 to 20 °C\n",
       "7         First Record:              2nd millennium BC\n",
       "8          Recorded By:           Egyptian astronomers"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup a Pandas DataFrame to store column data from \"cols\"\n",
    "mars_fact_df = pd.DataFrame(columns=['Parameters', 'Values'])\n",
    "\n",
    "mars_fact_df['Parameters'] = [cols[i][0] for i in range(len(cols))]\n",
    "mars_fact_df['Values'] = [cols[i][1] for i in range(len(cols))]\n",
    "\n",
    "# Display \"mars_fact_df\"\n",
    "mars_fact_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url for Mars facts on USGS Astrogeology\n",
    "hemisph_url= 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "\n",
    "# Navigate to url\n",
    "browser.visit(hemisph_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(browser.html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Cerberus Hemisphere Enhanced',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg'},\n",
       " {'title': 'Schiaparelli Hemisphere Enhanced',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg'},\n",
       " {'title': 'Syrtis Major Hemisphere Enhanced',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg'},\n",
       " {'title': 'Valles Marineris Hemisphere Enhanced',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List to store dict that containing hemisphere title and image url string  \n",
    "hemisph_img_urls = []\n",
    "\n",
    "# Find tags that contain 'div' with the class of \"item\"\n",
    "item_tags = soup.find_all('div', class_='item')\n",
    "\n",
    "# Loop through \"item\" tags\n",
    "for item in item_tags:\n",
    "    \n",
    "    # Retrieve hemisphere title\n",
    "    title = item.h3.text\n",
    "    \n",
    "    # Concatenate child_url\n",
    "    child_url = hemisph_url[:29] + item.find('a', class_='itemLink')['href']\n",
    "    \n",
    "    # Navigate to the child url\n",
    "    browser.visit(child_url)\n",
    "    \n",
    "    # Parse child url with BeautifulSoup\n",
    "    soup = BeautifulSoup(browser.html, 'html.parser')\n",
    "    \n",
    "    # Setup explicit wait time for javascript to load the webpage\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Concatenate the url for high resolution image\n",
    "    hi_r_img = hemisph_url[:29] + soup.find('img', class_='wide-image')['src']\n",
    "    \n",
    "    # Append hemisphere title and image url string to \"hemisph_img_urls\" as dict\n",
    "    hemisph_img_urls.append({'title': title, 'img_url': hi_r_img})\n",
    "    \n",
    "# View \"hemisph_img_urls\"\n",
    "hemisph_img_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close all browsers if still active\n",
    "browser.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
